from anthropic import Anthropic
from dotenv import load_dotenv
import os
import numpy as np
from sentence_transformers import SentenceTransformer
import json
from datetime import datetime
from typing import List, Dict, Tuple

# ===== –ó–ê–ì–†–£–ó–ö–ê API –ö–õ–Æ–ß–ê =====
load_dotenv()
api_key = os.getenv("ANTHROPIC_API_KEY")

if not api_key:
    print("–û—à–∏–±–∫–∞: API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω!")
    exit(1)

class RAGChatBot:
    def __init__(self):
        print("ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG —á–∞—Ç-–±–æ—Ç–∞...")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Claude
        self.client = Anthropic(api_key=api_key)
        self.model = "claude-3-haiku-20240307"
        
        # –ú–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞...")
        self.embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
        
        # –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –∫–æ–º–ø–∞–Ω–∏–∏
        self.knowledge_base = self._create_knowledge_base()
        
        # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
        print("üìù –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
        self.knowledge_texts = [doc["content"] for doc in self.knowledge_base]
        self.knowledge_embeddings = self.embedding_model.encode(self.knowledge_texts)
        
        # –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞
        self.conversation_history = []
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            "questions_asked": 0,
            "documents_used": 0,
            "sessions": 1
        }
        
        print("‚úÖ RAG —á–∞—Ç-–±–æ—Ç –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
        print(f"üìö –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π: {len(self.knowledge_base)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        print("-" * 60)
    
    def _create_knowledge_base(self) -> List[Dict]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π"""
        return [
            {
                "id": 1,
                "title": "–û—Å–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏",
                "content": "–ö–æ–º–ø–∞–Ω–∏—è NeuroTech Innovations –±—ã–ª–∞ –æ—Å–Ω–æ–≤–∞–Ω–∞ 15 –º–∞—Ä—Ç–∞ 2015 –≥–æ–¥–∞ –≤ –ú–æ—Å–∫–≤–µ. –û—Å–Ω–æ–≤–∞—Ç–µ–ª–∏: –ê–ª–µ–∫—Å–µ–π –ü–µ—Ç—Ä–æ–≤ (CEO) –∏ –ú–∞—Ä–∏—è –°–º–∏—Ä–Ω–æ–≤–∞ (CTO). –ú–∏—Å—Å–∏—è –∫–æ–º–ø–∞–Ω–∏–∏ - —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –ò–ò-—Ä–µ—à–µ–Ω–∏–π –¥–ª—è –º–µ–¥–∏—Ü–∏–Ω—ã.",
                "category": "–æ–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è",
                "date": "2015-03-15"
            },
            {
                "id": 2,
                "title": "–§–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏",
                "content": "–í 2023 –≥–æ–¥—É –∫–æ–º–ø–∞–Ω–∏—è –ø—Ä–∏–≤–ª–µ–∫–ª–∞ $50 –º–∏–ª–ª–∏–æ–Ω–æ–≤ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π –≤ —Ä–∞—É–Ω–¥–µ Series B. –û—Å–Ω–æ–≤–Ω—ã–µ –∏–Ω–≤–µ—Å—Ç–æ—Ä—ã: Sequoia Capital, —Ñ–æ–Ω–¥ –°–±–µ—Ä–±–∞–Ω–∫–∞ –∏ Y Combinator. –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–æ–º–ø–∞–Ω–∏–∏ –ø–æ—Å–ª–µ —Ä–∞—É–Ω–¥–∞ - $300 –º–∏–ª–ª–∏–æ–Ω–æ–≤.",
                "category": "—Ñ–∏–Ω–∞–Ω—Å—ã",
                "date": "2023-06-20"
            },
            {
                "id": 3,
                "title": "–ö–æ–º–∞–Ω–¥–∞ –∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∏",
                "content": "–í –∫–æ–º–ø–∞–Ω–∏–∏ —Ä–∞–±–æ—Ç–∞–µ—Ç 250 —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: 150 –∏–Ω–∂–µ–Ω–µ—Ä–æ–≤ –∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–µ–π, 50 –≤—Ä–∞—á–µ–π-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç–æ–≤, 30 –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤ –ø—Ä–æ–¥—É–∫—Ç–∞, 20 —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –æ—Ç–¥–µ–ª–∞ –ø—Ä–æ–¥–∞–∂. –®—Ç–∞–±-–∫–≤–∞—Ä—Ç–∏—Ä–∞ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –ú–æ—Å–∫–≤–µ, –µ—Å—Ç—å –æ—Ñ–∏—Å—ã –≤ –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥–µ –∏ –ë–µ—Ä–ª–∏–Ω–µ.",
                "category": "–∫–æ–º–∞–Ω–¥–∞",
                "date": "2024-01-15"
            },
            {
                "id": 4,
                "title": "–ü—Ä–æ–¥—É–∫—Ç NeuroCloud",
                "content": "–û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–¥—É–∫—Ç - –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ NeuroCloud –≤–µ—Ä—Å–∏–∏ 2.1. –≠—Ç–æ –æ–±–ª–∞—á–Ω–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (—Ä–µ–Ω—Ç–≥–µ–Ω, –ú–†–¢, –ö–¢). –¢–æ—á–Ω–æ—Å—Ç—å –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç 96.5%. –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ 50 –±–æ–ª—å–Ω–∏—Ü–∞—Ö –ø–æ –†–æ—Å—Å–∏–∏.",
                "category": "–ø—Ä–æ–¥—É–∫—Ç—ã",
                "date": "2024-02-01"
            },
            {
                "id": 5,
                "title": "–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è",
                "content": "–ö–æ–º–ø–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ–¥–µ–ª–∏ –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤. –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏: Python, PyTorch, FastAPI, PostgreSQL. –û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ 15 –Ω–∞—É—á–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π –≤ –∂—É—Ä–Ω–∞–ª–∞—Ö Nature –∏ Science. –ü–æ–ª—É—á–µ–Ω–æ 5 –ø–∞—Ç–µ–Ω—Ç–æ–≤ –Ω–∞ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏.",
                "category": "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏",
                "date": "2024-03-10"
            },
            {
                "id": 6,
                "title": "–ü–∞—Ä—Ç–Ω–µ—Ä—ã –∏ –∫–ª–∏–µ–Ω—Ç—ã",
                "content": "–ö–ª—é—á–µ–≤—ã–µ –ø–∞—Ä—Ç–Ω–µ—Ä—ã: Mayo Clinic (–°–®–ê), Charit√© (–ì–µ—Ä–º–∞–Ω–∏—è), –ú–æ—Å–∫–æ–≤—Å–∫–∞—è –≥–æ—Ä–æ–¥—Å–∫–∞—è –±–æ–ª—å–Ω–∏—Ü–∞ ‚Ññ1. –í—Å–µ–≥–æ –∫–æ–º–ø–∞–Ω–∏—è —Å–æ—Ç—Ä—É–¥–Ω–∏—á–∞–µ—Ç —Å 50 –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–º–∏ —É—á—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏ –≤ –†–æ—Å—Å–∏–∏ –∏ 20 - –∑–∞ —Ä—É–±–µ–∂–æ–º. –í 2024 –≥–æ–¥—É –ø–ª–∞–Ω–∏—Ä—É–µ—Ç—Å—è –≤—ã—Ö–æ–¥ –Ω–∞ —Ä—ã–Ω–æ–∫ –ê–∑–∏–∏.",
                "category": "–ø–∞—Ä—Ç–Ω–µ—Ä—ã",
                "date": "2024-01-30"
            },
            {
                "id": 7,
                "title": "–ù–∞–≥—Ä–∞–¥—ã –∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è",
                "content": "2022 - –ü—Ä–µ–º–∏—è '–õ—É—á—à–∏–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π —Å—Ç–∞—Ä—Ç–∞–ø' –Ω–∞ AI Healthcare Summit. 2023 - –°–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è FDA –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ —Ä–∞–∫–∞ –ª–µ–≥–∫–∏—Ö. 2024 - –¢–æ–ø-10 –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∏–Ω–Ω–æ–≤–∞—Ü–∏–π –ø–æ –≤–µ—Ä—Å–∏–∏ Forbes.",
                "category": "–¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è",
                "date": "2024-04-05"
            },
            {
                "id": 8,
                "title": "–ü–ª–∞–Ω—ã –Ω–∞ –±—É–¥—É—â–µ–µ",
                "content": "–í —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ NeuroCloud 3.0 —Å –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–º –ò–ò. –ü–ª–∞–Ω–∏—Ä—É–µ—Ç—Å—è –∑–∞–ø—É—Å–∫ –º–æ–±–∏–ª—å–Ω–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –¥–ª—è –≤—Ä–∞—á–µ–π. –¶–µ–ª—å –Ω–∞ 2025 –≥–æ–¥ - –æ—Ö–≤–∞—Ç–∏—Ç—å 100 –±–æ–ª—å–Ω–∏—Ü –≤ –ï–≤—Ä–æ–ø–µ –∏ –°–®–ê.",
                "category": "–ø–ª–∞–Ω—ã",
                "date": "2024-05-12"
            }
        ]
    
    def _search_in_knowledge_base(self, query: str, top_k: int = 3) -> List[Dict]:
        """–ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π"""
        # –≠–º–±–µ–¥–¥–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞
        query_embedding = self.embedding_model.encode(query)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        query_norm = query_embedding / np.linalg.norm(query_embedding)
        doc_norms = self.knowledge_embeddings / np.linalg.norm(self.knowledge_embeddings, axis=1, keepdims=True)
        
        # –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
        similarities = np.dot(doc_norms, query_norm)
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø-K –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        top_indices = np.argsort(similarities)[-top_k:][::-1]
        
        results = []
        for idx in top_indices:
            doc = self.knowledge_base[idx].copy()
            doc["similarity"] = float(similarities[idx])
            doc["relevance_percent"] = int(similarities[idx] * 100)
            results.append(doc)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –ø–æ—Ä–æ–≥—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        threshold = 0.4
        filtered_results = [doc for doc in results if doc["similarity"] >= threshold]
        
        return filtered_results if filtered_results else results[:1]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω
    
    def _format_conversation_history(self, max_messages: int = 6) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞"""
        if not self.conversation_history:
            return ""
        
        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Å–æ–æ–±—â–µ–Ω–∏–π
        recent_history = self.conversation_history[-max_messages:]
        
        formatted = "–ò–°–¢–û–†–ò–Ø –î–ò–ê–õ–û–ì–ê:\n"
        for msg in recent_history:
            role = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" if msg["role"] == "user" else "–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç"
            formatted += f"{role}: {msg['content']}\n"
        
        return formatted
    
    def _format_sources(self, sources: List[Dict]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è –æ—Ç–≤–µ—Ç–∞"""
        if not sources:
            return "–ò—Å—Ç–æ—á–Ω–∏–∫–∏: –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –æ–±—â–µ–π –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π"
        
        formatted = "üìö –ò–°–¢–û–ß–ù–ò–ö–ò –ò–ù–§–û–†–ú–ê–¶–ò–ò:\n"
        for i, source in enumerate(sources, 1):
            formatted += f"\n{i}. üìÑ {source['title']}\n"
            formatted += f"   üè∑Ô∏è  –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {source['category']}\n"
            formatted += f"   üìÖ –î–∞—Ç–∞: {source['date']}\n"
            formatted += f"   üìä –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {source['relevance_percent']}%\n"
            if i < len(sources):
                formatted += "   " + "-" * 40 + "\n"
        
        return formatted
    
    def ask(self, user_message: str) -> Dict:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–æ–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        print(f"\n{'='*60}")
        print(f"üí¨ –í–û–ü–†–û–°: {user_message}")
        print(f"{'='*60}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤–æ–ø—Ä–æ—Å –≤ –∏—Å—Ç–æ—Ä–∏—é
        self.conversation_history.append({
            "role": "user",
            "content": user_message,
            "timestamp": datetime.now().isoformat()
        })
        
        # –®–∞–≥ 1: –ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
        print("üîç –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏...")
        relevant_docs = self._search_in_knowledge_base(user_message)
        
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(relevant_docs)}")
        for doc in relevant_docs:
            print(f"   ‚Ä¢ {doc['title']} ({doc['relevance_percent']}% —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏)")
        
        # –®–∞–≥ 2: –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context = "–ò–ù–§–û–†–ú–ê–¶–ò–Ø –ò–ó –ë–ê–ó–´ –ó–ù–ê–ù–ò–ô –ö–û–ú–ü–ê–ù–ò–ò:\n\n"
        for doc in relevant_docs:
            context += f"–î–æ–∫—É–º–µ–Ω—Ç: {doc['title']}\n"
            context += f"–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: {doc['content']}\n\n"
        
        # –®–∞–≥ 3: –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç —Å –∏—Å—Ç–æ—Ä–∏–µ–π
        history = self._format_conversation_history()
        
        prompt = f"""{history}

{context}

–¢–ï–ö–£–©–ò–ô –í–û–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: {user_message}

–ò–ù–°–¢–†–£–ö–¶–ò–ò:
1. –û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
2. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, —Ç–∞–∫ –∏ —Å–∫–∞–∂–∏
3. –ë—É–¥—å —Ç–æ—á–Ω—ã–º –∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º
4. –ò—Å–ø–æ–ª—å–∑—É–π —Ñ–∞–∫—Ç—ã –∏ —Ü–∏—Ñ—Ä—ã –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
5. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ

–û–¢–í–ï–¢:"""
        
        # –®–∞–≥ 4: –ó–∞–ø—Ä–æ—Å –∫ Claude
        print("ü§ñ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞...")
        try:
            response = self.client.messages.create(
                model=self.model,
                max_tokens=1000,
                temperature=0.3,
                system="–¢—ã - –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –∫–æ–º–ø–∞–Ω–∏–∏ NeuroTech, –∫–æ—Ç–æ—Ä—ã–π –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –∏ –∫–ª–∏–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –∫–æ–º–ø–∞–Ω–∏–∏.",
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )
            
            answer = response.content[0].text
            
        except Exception as e:
            answer = f"–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}"
        
        # –®–∞–≥ 5: –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç —Å –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏
        sources_text = self._format_sources(relevant_docs)
        full_response = f"{answer}\n\n{sources_text}"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –≤ –∏—Å—Ç–æ—Ä–∏—é
        self.conversation_history.append({
            "role": "assistant",
            "content": answer,
            "timestamp": datetime.now().isoformat(),
            "sources": [doc["id"] for doc in relevant_docs]
        })
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.stats["questions_asked"] += 1
        self.stats["documents_used"] += len(relevant_docs)
        
        return {
            "answer": answer,
            "sources": relevant_docs,
            "sources_text": sources_text,
            "full_response": full_response,
            "stats": self.stats.copy()
        }
    
    def clear_history(self):
        """–û—á–∏—Å—Ç–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞"""
        self.conversation_history = []
        print("üóëÔ∏è  –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –æ—á–∏—â–µ–Ω–∞")
    
    def show_stats(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        print("\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ß–ê–¢-–ë–û–¢–ê:")
        print(f"   ‚Ä¢ –ó–∞–¥–∞–Ω–æ –≤–æ–ø—Ä–æ—Å–æ–≤: {self.stats['questions_asked']}")
        print(f"   ‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {self.stats['documents_used']}")
        print(f"   ‚Ä¢ –°–µ—Å—Å–∏–π: {self.stats['sessions']}")
        print(f"   ‚Ä¢ –°–æ–æ–±—â–µ–Ω–∏–π –≤ –∏—Å—Ç–æ—Ä–∏–∏: {len(self.conversation_history)}")
        
        if self.conversation_history:
            last_time = self.conversation_history[-1]['timestamp']
            print(f"   ‚Ä¢ –ü–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: {last_time[:19]}")
    
    def save_conversation(self, filename: str = None):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞ –≤ —Ñ–∞–π–ª"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"conversation_{timestamp}.json"
        
        data = {
            "conversation": self.conversation_history,
            "stats": self.stats,
            "timestamp": datetime.now().isoformat()
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"üíæ –î–∏–∞–ª–æ–≥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: {filename}")
        return filename
    
    def show_knowledge_base(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å –±–∞–∑—É –∑–Ω–∞–Ω–∏–π"""
        print("\nüìö –ë–ê–ó–ê –ó–ù–ê–ù–ò–ô –ö–û–ú–ü–ê–ù–ò–ò:")
        print(f"–í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(self.knowledge_base)}")
        print("-" * 60)
        
        for doc in self.knowledge_base:
            print(f"\nüìÑ –î–æ–∫—É–º–µ–Ω—Ç #{doc['id']}: {doc['title']}")
            print(f"   üè∑Ô∏è  –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {doc['category']}")
            print(f"   üìÖ –î–∞—Ç–∞: {doc['date']}")
            print(f"   üìù {doc['content'][:150]}...")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è - –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —á–∞—Ç"""
    print("üí¨ –ù–ï–ô–†–û–¢–ï–• –ß–ê–¢-–ë–û–¢ –° –ü–ê–ú–Ø–¢–¨–Æ –ò RAG")
    print("="*60)
    print("–Ø - –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –∫–æ–º–ø–∞–Ω–∏–∏ NeuroTech Innovations.")
    print("–û—Ç–≤–µ—á–∞—é –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ –∫–æ–º–ø–∞–Ω–∏–∏, –∏—Å–ø–æ–ª—å–∑—É—è –±–∞–∑—É –∑–Ω–∞–Ω–∏–π.")
    print("="*60)
    
    # –°–æ–∑–¥–∞–µ–º –±–æ—Ç–∞
    bot = RAGChatBot()
    
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
    demo_questions = [
        "–ö–æ–≥–¥–∞ –±—ã–ª–∞ –æ—Å–Ω–æ–≤–∞–Ω–∞ –∫–æ–º–ø–∞–Ω–∏—è?",
        "–°–∫–æ–ª—å–∫–æ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π –≤—ã –ø—Ä–∏–≤–ª–µ–∫–ª–∏?",
        "–°–∫–æ–ª—å–∫–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ —É –≤–∞—Å —Ä–∞–±–æ—Ç–∞–µ—Ç?",
        "–ß—Ç–æ —Ç–∞–∫–æ–µ NeuroCloud?",
        "–° –∫–∞–∫–∏–º–∏ –±–æ–ª—å–Ω–∏—Ü–∞–º–∏ –≤—ã —Å–æ—Ç—Ä—É–¥–Ω–∏—á–∞–µ—Ç–µ?"
    ]
    
    print("\nüí° –ü—Ä–∏–º–µ—Ä—ã –≤–æ–ø—Ä–æ—Å–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å:")
    for i, question in enumerate(demo_questions, 1):
        print(f"   {i}. {question}")
    
    print("\n" + "="*60)
    print("üéÆ –ö–û–ú–ê–ù–î–´ –ß–ê–¢–ê:")
    print("   /help     - –ü–æ–∫–∞–∑–∞—Ç—å –ø–æ–º–æ—â—å")
    print("   /stats    - –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É")
    print("   /clear    - –û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é")
    print("   /save     - –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–∏–∞–ª–æ–≥")
    print("   /kb       - –ü–æ–∫–∞–∑–∞—Ç—å –±–∞–∑—É –∑–Ω–∞–Ω–∏–π")
    print("   /demo     - –ó–∞–ø—É—Å—Ç–∏—Ç—å –¥–µ–º–æ-–¥–∏–∞–ª–æ–≥")
    print("   /exit     - –í—ã–π—Ç–∏ –∏–∑ —á–∞—Ç–∞")
    print("="*60)
    
    # –ì–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª —á–∞—Ç–∞
    while True:
        try:
            # –í–≤–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            user_input = input("\nüë§ –í—ã: ").strip()
            
            if not user_input:
                continue
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥
            if user_input.lower() == '/exit':
                print("\nüëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è! –°–ø–∞—Å–∏–±–æ –∑–∞ –æ–±—â–µ–Ω–∏–µ!")
                bot.save_conversation()
                break
            
            elif user_input.lower() == '/help':
                print("\nüìã –ü–û–ú–û–©–¨:")
                print("   ‚Ä¢ –ó–∞–¥–∞–≤–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å—ã –æ –∫–æ–º–ø–∞–Ω–∏–∏ NeuroTech")
                print("   ‚Ä¢ –ë–æ—Ç –∏—â–µ—Ç –æ—Ç–≤–µ—Ç—ã –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π")
                print("   ‚Ä¢ –ö–∞–∂–¥—ã–π –æ—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏")
                print("   ‚Ä¢ –ë–æ—Ç –ø–æ–º–Ω–∏—Ç –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞")
                print("\nüí° –ü—Ä–∏–º–µ—Ä—ã –≤–æ–ø—Ä–æ—Å–æ–≤:")
                for q in demo_questions:
                    print(f"   - {q}")
                continue
            
            elif user_input.lower() == '/stats':
                bot.show_stats()
                continue
            
            elif user_input.lower() == '/clear':
                bot.clear_history()
                continue
            
            elif user_input.lower() == '/save':
                filename = bot.save_conversation()
                print(f"‚úÖ –î–∏–∞–ª–æ–≥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫ {filename}")
                continue
            
            elif user_input.lower() == '/kb':
                bot.show_knowledge_base()
                continue
            
            elif user_input.lower() == '/demo':
                print("\nüß™ –ó–ê–ü–£–°–ö –î–ï–ú–û-–î–ò–ê–õ–û–ì–ê...")
                for question in demo_questions:
                    print(f"\n{'='*60}")
                    print(f"üë§ –í—ã: {question}")
                    
                    response = bot.ask(question)
                    print(f"\nü§ñ –ë–æ—Ç: {response['answer'][:200]}...")
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∫—Ä–∞—Ç–∫–æ
                    if response['sources']:
                        print(f"\nüìö –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {len(response['sources'])}")
                        for source in response['sources']:
                            print(f"   ‚Ä¢ {source['title']} ({source['relevance_percent']}%)")
                
                print("\n‚úÖ –î–µ–º–æ-–¥–∏–∞–ª–æ–≥ –∑–∞–≤–µ—Ä—à–µ–Ω")
                continue
            
            # –û–±—ã—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            print(f"\n{'='*60}")
            print(f"üë§ –í–ê–® –í–û–ü–†–û–°: {user_input}")
            print(f"{'='*60}")
            
            # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –±–æ—Ç–∞
            response = bot.ask(user_input)
            
            # –í—ã–≤–æ–¥–∏–º –æ—Ç–≤–µ—Ç
            print(f"\n{'='*60}")
            print("ü§ñ –û–¢–í–ï–¢ –ë–û–¢–ê:")
            print(f"{'='*60}")
            print(response['answer'])
            
            # –í—ã–≤–æ–¥–∏–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏
            print(f"\n{'='*60}")
            print("üìö –ò–°–¢–û–ß–ù–ò–ö–ò –ò–ù–§–û–†–ú–ê–¶–ò–ò:")
            print(f"{'='*60}")
            print(response['sources_text'])
            
            # –ö—Ä–∞—Ç–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            print(f"\n‚ÑπÔ∏è  –î–ª—è —ç—Ç–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ {len(response['sources'])} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            print(f"üìà –í—Å–µ–≥–æ –≤–æ–ø—Ä–æ—Å–æ–≤ –≤ –¥–∏–∞–ª–æ–≥–µ: {response['stats']['questions_asked']}")
        
        except KeyboardInterrupt:
            print("\n\n‚ö†Ô∏è  –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            save = input("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–∏–∞–ª–æ–≥ –ø–µ—Ä–µ–¥ –≤—ã—Ö–æ–¥–æ–º? (–¥–∞/–Ω–µ—Ç): ").lower()
            if save in ['–¥–∞', '–¥', 'yes', 'y']:
                bot.save_conversation()
            print("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
            break
        
        except Exception as e:
            print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
            print("–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –≤–≤–µ–¥–∏—Ç–µ /help –¥–ª—è –ø–æ–º–æ—â–∏")

if __name__ == "__main__":
    main()