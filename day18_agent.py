from anthropic import Anthropic
from dotenv import load_dotenv
import os
import numpy as np
from sentence_transformers import SentenceTransformer

# ===== –ó–ê–ì–†–£–ó–ö–ê API –ö–õ–Æ–ß–ê =====
load_dotenv()
api_key = os.getenv("ANTHROPIC_API_KEY")

if not api_key:
    print("–û—à–∏–±–∫–∞: API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω!")
    exit(1)

# –ü—Ä–æ—Å—Ç–æ–π RAG —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π
class SimpleRAG:
    def __init__(self):
        print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG —Å–∏—Å—Ç–µ–º—ã...")
        
        self.client = Anthropic(api_key=api_key)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
        self.embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
        
        # –ù–∞—à–∞ –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π
        self.documents = [
            "–ö–æ–º–ø–∞–Ω–∏—è NeuroTech Innovations –±—ã–ª–∞ –æ—Å–Ω–æ–≤–∞–Ω–∞ 15 –º–∞—Ä—Ç–∞ 2015 –≥–æ–¥–∞ –≤ –ú–æ—Å–∫–≤–µ.",
            "–û—Å–Ω–æ–≤–∞—Ç–µ–ª–∏ –∫–æ–º–ø–∞–Ω–∏–∏: –ê–ª–µ–∫—Å–µ–π –ü–µ—Ç—Ä–æ–≤ (CEO) –∏ –ú–∞—Ä–∏—è –°–º–∏—Ä–Ω–æ–≤–∞ (CTO).",
            "–í 2023 –≥–æ–¥—É –∫–æ–º–ø–∞–Ω–∏—è –ø—Ä–∏–≤–ª–µ–∫–ª–∞ $50 –º–∏–ª–ª–∏–æ–Ω–æ–≤ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π.",
            "–û—Å–Ω–æ–≤–Ω—ã–µ –∏–Ω–≤–µ—Å—Ç–æ—Ä—ã: Sequoia Capital –∏ —Ñ–æ–Ω–¥ –°–±–µ—Ä–±–∞–Ω–∫–∞.",
            "–í –∫–æ–º–ø–∞–Ω–∏–∏ —Ä–∞–±–æ—Ç–∞–µ—Ç 250 —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤.",
            "–ò–∑ –Ω–∏—Ö 150 - –∏–Ω–∂–µ–Ω–µ—Ä—ã –∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ò–ò.",
            "–û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–¥—É–∫—Ç - –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ NeuroCloud –≤–µ—Ä—Å–∏–∏ 2.1.",
            "–ü–ª–∞—Ç—Ñ–æ—Ä–º–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å —Ç–æ—á–Ω–æ—Å—Ç—å—é 96.5%.",
            "–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç - —ç—Ç–æ –æ–±–ª–∞—Å—Ç—å –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω—ã—Ö –Ω–∞—É–∫.",
            "–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —è–≤–ª—è–µ—Ç—Å—è –ø–æ–¥—Ä–∞–∑–¥–µ–ª–æ–º –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞.",
            "–°—Ç–∞—Ä—Ç–∞–ø—ã —á–∞—Å—Ç–æ –ø—Ä–∏–≤–ª–µ–∫–∞—é—Ç –≤–µ–Ω—á—É—Ä–Ω—ã–µ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏.",
            "–ö—Ä–µ–º–Ω–∏–µ–≤–∞—è –¥–æ–ª–∏–Ω–∞ - —Ü–µ–Ω—Ç—Ä —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –∏–Ω–Ω–æ–≤–∞—Ü–∏–π."
        ]
        
        # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        print("üìù –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
        self.document_embeddings = self.embedding_model.encode(self.documents)
        
        print(f"‚úÖ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞! –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        print("-" * 50)
    
    def calculate_similarity(self, query, document_embeddings):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞"""
        query_embedding = self.embedding_model.encode(query)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤
        query_norm = query_embedding / np.linalg.norm(query_embedding)
        doc_norms = document_embeddings / np.linalg.norm(document_embeddings, axis=1, keepdims=True)
        
        # –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
        similarities = np.dot(doc_norms, query_norm)
        return similarities
    
    def search_without_filter(self, query, top_k=5):
        """–ü–æ–∏—Å–∫ –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏"""
        print(f"\nüîç –ü–û–ò–°–ö –ë–ï–ó –§–ò–õ–¨–¢–†–ê–¶–ò–ò")
        print(f"–ó–∞–ø—Ä–æ—Å: '{query}'")
        
        similarities = self.calculate_similarity(query, self.document_embeddings)
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø-K –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        top_indices = np.argsort(similarities)[-top_k:][::-1]
        
        print(f"–ù–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(top_indices)}")
        print("–¢–æ–ø –¥–æ–∫—É–º–µ–Ω—Ç—ã:")
        
        results = []
        for i, idx in enumerate(top_indices, 1):
            similarity = similarities[idx]
            doc = self.documents[idx]
            results.append((doc, similarity))
            
            print(f"{i}. [–°—Ö–æ–¥—Å—Ç–≤–æ: {similarity:.3f}] {doc}")
        
        return results
    
    def search_with_filter(self, query, threshold=0.5, top_k=10):
        """–ü–æ–∏—Å–∫ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ –ø–æ—Ä–æ–≥—É"""
        print(f"\nüîç –ü–û–ò–°–ö –° –§–ò–õ–¨–¢–†–ê–¶–ò–ï–ô (–ø–æ—Ä–æ–≥: {threshold})")
        print(f"–ó–∞–ø—Ä–æ—Å: '{query}'")
        
        similarities = self.calculate_similarity(query, self.document_embeddings)
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –ø–æ—Ä–æ–≥—É
        filtered_indices = [i for i, sim in enumerate(similarities) if sim >= threshold]
        
        if not filtered_indices:
            print(f"‚ùå –ù–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å —Å—Ö–æ–¥—Å—Ç–≤–æ–º >= {threshold}")
            return []
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        filtered_similarities = [similarities[i] for i in filtered_indices]
        sorted_indices = [x for _, x in sorted(zip(filtered_similarities, filtered_indices), reverse=True)]
        
        # –ë–µ—Ä–µ–º —Ç–æ–ø-K
        top_indices = sorted_indices[:top_k]
        
        print(f"–í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(self.documents)}")
        print(f"–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {len(top_indices)}/{len(filtered_indices)}")
        print("–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã:")
        
        results = []
        for i, idx in enumerate(top_indices, 1):
            similarity = similarities[idx]
            doc = self.documents[idx]
            results.append((doc, similarity))
            
            print(f"{i}. [–°—Ö–æ–¥—Å—Ç–≤–æ: {similarity:.3f}] {doc}")
        
        return results
    
    def ask_claude(self, query, context=""):
        """–ó–∞–ø—Ä–æ—Å –∫ Claude"""
        try:
            if context:
                prompt = f"""–ò—Å–ø–æ–ª—å–∑—É–π —Å–ª–µ–¥—É—é—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å:
                
{context}

–í–æ–ø—Ä–æ—Å: {query}

–û—Ç–≤–µ—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º."""
            else:
                prompt = query
            
            response = self.client.messages.create(
                model="claude-3-haiku-20240307",
                max_tokens=500,
                temperature=0.3,
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )
            
            return response.content[0].text
            
        except Exception as e:
            return f"–û—à–∏–±–∫–∞: {str(e)}"
    
    def compare_approaches(self, query):
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ–¥—Ö–æ–¥–æ–≤ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –∏ –±–µ–∑"""
        print("\n" + "="*60)
        print("üîÑ –°–†–ê–í–ù–ï–ù–ò–ï –ü–û–î–•–û–î–û–í")
        print("="*60)
        
        # 1. –ë–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        print("\n1Ô∏è‚É£  –ë–ï–ó –§–ò–õ–¨–¢–†–ê–¶–ò–ò:")
        results_no_filter = self.search_without_filter(query)
        
        if results_no_filter:
            context_no_filter = "\n".join([doc for doc, _ in results_no_filter[:3]])
            answer_no_filter = self.ask_claude(query, context_no_filter)
            print(f"\nüìù –û–¢–í–ï–¢ –ë–ï–ó –§–ò–õ–¨–¢–†–ê–¶–ò–ò:")
            print(answer_no_filter)
        
        # 2. –° —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π
        print("\n2Ô∏è‚É£  –° –§–ò–õ–¨–¢–†–ê–¶–ò–ï–ô (–ø–æ—Ä–æ–≥ 0.5):")
        results_with_filter = self.search_with_filter(query, threshold=0.5)
        
        if results_with_filter:
            context_with_filter = "\n".join([doc for doc, _ in results_with_filter[:3]])
            answer_with_filter = self.ask_claude(query, context_with_filter)
            print(f"\nüìù –û–¢–í–ï–¢ –° –§–ò–õ–¨–¢–†–ê–¶–ò–ï–ô:")
            print(answer_with_filter)
        
        # 3. –ê–Ω–∞–ª–∏–∑
        print("\n" + "="*60)
        print("üìä –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
        print("="*60)
        
        if results_no_filter and results_with_filter:
            print(f"‚Ä¢ –î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞: {len(results_no_filter)}")
            print(f"‚Ä¢ –î–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å —Ñ–∏–ª—å—Ç—Ä–æ–º: {len(results_with_filter)}")
            print(f"‚Ä¢ –£–¥–∞–ª–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(results_no_filter) - len(results_with_filter)}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
            key_terms = ["2015", "15 –º–∞—Ä—Ç–∞", "$50", "250", "NeuroCloud", "96.5%"]
            has_key_terms_no_filter = any(term in answer_no_filter for term in key_terms)
            has_key_terms_with_filter = any(term in answer_with_filter for term in key_terms)
            
            print(f"\nüîë –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã –≤ –æ—Ç–≤–µ—Ç–∞—Ö:")
            print(f"   –ë–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞: {'‚úÖ' if has_key_terms_no_filter else '‚ùå'}")
            print(f"   –° —Ñ–∏–ª—å—Ç—Ä–æ–º: {'‚úÖ' if has_key_terms_with_filter else '‚ùå'}")
            
            if has_key_terms_with_filter and not has_key_terms_no_filter:
                print("\nüéØ –í–´–í–û–î: –§–ò–õ–¨–¢–†–ê–¶–ò–Ø –ü–û–ú–û–ì–õ–ê - –æ—Ç–≤–µ—Ç —Å—Ç–∞–ª –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–º!")
            elif has_key_terms_with_filter and has_key_terms_no_filter:
                print("\n‚öñÔ∏è  –í–´–í–û–î: –û–±–∞ –ø–æ–¥—Ö–æ–¥–∞ –¥–∞–ª–∏ —Ö–æ—Ä–æ—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
            else:
                print("\n‚ö†Ô∏è  –í–´–í–û–î: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –Ω–µ —É–ª—É—á—à–∏–ª–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
        
        elif results_with_filter and not results_no_filter:
            print("‚ùå –ë–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –Ω–æ —Å —Ñ–∏–ª—å—Ç—Ä–æ–º - –Ω–∞–π–¥–µ–Ω—ã!")
        elif not results_with_filter and results_no_filter:
            print("‚ö†Ô∏è  –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —É–¥–∞–ª–∏–ª–∞ –í–°–ï –¥–æ–∫—É–º–µ–Ω—Ç—ã - –≤–æ–∑–º–æ–∂–Ω–æ, –ø–æ—Ä–æ–≥ —Å–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∏–π")
        else:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–∏ —Å –æ–¥–Ω–∏–º –∏–∑ –ø–æ–¥—Ö–æ–¥–æ–≤")

# –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
def main():
    print("ü§ñ RAG –°–ò–°–¢–ï–ú–ê –° –§–ò–õ–¨–¢–†–ê–¶–ò–ï–ô –ò –†–ï–†–ê–ù–ö–ò–ù–ì–û–ú")
    print("="*60)
    
    # –°–æ–∑–¥–∞–µ–º RAG —Å–∏—Å—Ç–µ–º—É
    rag = SimpleRAG()
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã
    test_questions = [
        "–ö–æ–≥–¥–∞ –±—ã–ª–∞ –æ—Å–Ω–æ–≤–∞–Ω–∞ –∫–æ–º–ø–∞–Ω–∏—è NeuroTech?",
        "–°–∫–æ–ª—å–∫–æ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π –ø—Ä–∏–≤–ª–µ–∫–ª–∞ –∫–æ–º–ø–∞–Ω–∏—è?",
        "–°–∫–æ–ª—å–∫–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ –∫–æ–º–ø–∞–Ω–∏–∏?",
        "–ö–∞–∫–æ–π –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–¥—É–∫—Ç —É –∫–æ–º–ø–∞–Ω–∏–∏ –∏ –∫–∞–∫–∞—è —É –Ω–µ–≥–æ —Ç–æ—á–Ω–æ—Å—Ç—å?",
        "–ß—Ç–æ —Ç–∞–∫–æ–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç?"  # –û–±—â–∏–π –≤–æ–ø—Ä–æ—Å
    ]
    
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ—Å—Ç
    print("\nüß™ –ó–ê–ü–£–°–ö –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–û–ì–û –¢–ï–°–¢–ê")
    print("="*60)
    
    for i, question in enumerate(test_questions, 1):
        print(f"\n{'#'*60}")
        print(f"–¢–ï–°–¢ {i}/{len(test_questions)}")
        print(f"–í–û–ü–†–û–°: {question}")
        print(f"{'#'*60}")
        
        rag.compare_approaches(question)
        
        # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –≤–æ–ø—Ä–æ—Å–∞–º–∏
        if i < len(test_questions):
            input("\n–ù–∞–∂–º–∏ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")
    
    # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º
    print("\n" + "="*60)
    print("üéÆ –ò–ù–¢–ï–†–ê–ö–¢–ò–í–ù–´–ô –†–ï–ñ–ò–ú")
    print("="*60)
    
    while True:
        print("\n–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:")
        print("1 - –ó–∞–¥–∞—Ç—å –Ω–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å")
        print("2 - –ò–∑–º–µ–Ω–∏—Ç—å –ø–æ—Ä–æ–≥ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")
        print("3 - –ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã")
        print("0 - –í—ã—Ö–æ–¥")
        
        choice = input("\nüëâ –í–∞—à –≤—ã–±–æ—Ä: ").strip()
        
        if choice == "1":
            question = input("\nü§î –í–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å: ")
            rag.compare_approaches(question)
        
        elif choice == "2":
            try:
                new_threshold = float(input(f"\nüìè –í–≤–µ–¥–∏—Ç–µ –Ω–æ–≤—ã–π –ø–æ—Ä–æ–≥ (—Ç–µ–∫—É—â–∏–π 0.5, –æ—Ç 0 –¥–æ 1): "))
                if 0 <= new_threshold <= 1:
                    print(f"\nüîÑ –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å –ø–æ—Ä–æ–≥–æ–º {new_threshold}...")
                    question = "–ö–æ–≥–¥–∞ –±—ã–ª–∞ –æ—Å–Ω–æ–≤–∞–Ω–∞ –∫–æ–º–ø–∞–Ω–∏—è NeuroTech?"
                    rag.search_with_filter(question, threshold=new_threshold)
                else:
                    print("‚ùå –ü–æ—Ä–æ–≥ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –º–µ–∂–¥—É 0 –∏ 1")
            except:
                print("‚ùå –í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ")
        
        elif choice == "3":
            print(f"\nüìö –í–°–ï –î–û–ö–£–ú–ï–ù–¢–´ ({len(rag.documents)}):")
            for i, doc in enumerate(rag.documents, 1):
                print(f"{i}. {doc}")
        
        elif choice == "0":
            print("\nüëã –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã...")
            break
        
        else:
            print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä")

if __name__ == "__main__":
    main()